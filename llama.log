[1717469298] warming up the model with an empty run
[1717469298] 
[1717469298] llama server listening at http://172.17.0.2:8080
[1717469298] llama server listening at http://127.0.0.1:8080
[1717469298] 
